{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "79767d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import json\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4bd828af",
   "metadata": {},
   "outputs": [],
   "source": [
    "MATCHED_PATH = \"lpd_5/lpd_5_matched/\"\n",
    "CLEANED_PATH = \"lpd_5/lpd_5_cleansed/\"\n",
    "MUMU_AMAZON_PATH = \"MuMu_dataset/amazon_reviews_MuMu.json\"\n",
    "MUMU_MULTI_PATH = \"MuMu_dataset/MuMu_dataset_multi-label.csv\"\n",
    "MUMU_SINGLE_PATH = \"MuMu_dataset/MuMu_dataset_single-label.csv\"\n",
    "\n",
    "matched_file_paths = []\n",
    "for x in os.walk(MATCHED_PATH):\n",
    "    for y in glob.glob(os.path.join(x[0], '*.npz')):\n",
    "        matched_file_paths.append(y)\n",
    "\n",
    "cleaned_file_paths = []\n",
    "for x in os.walk(CLEANED_PATH):\n",
    "    for y in glob.glob(os.path.join(x[0], '*.npz')):\n",
    "        cleaned_file_paths.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f36e25b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115160 21425\n"
     ]
    }
   ],
   "source": [
    "# total number of songs\n",
    "print(len(matched_file_paths), len(cleaned_file_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "1b1cf88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mumu_multi_df = pd.read_csv(MUMU_MULTI_PATH)\n",
    "mumu_single_df = pd.read_csv(MUMU_SINGLE_PATH)\n",
    "mumu_amazon_df = pd.read_json(MUMU_AMAZON_PATH, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "28c9a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of MSD and recording ids of the piano roll dataset\n",
    "cleaned_MSD_id_list = []\n",
    "uncleaned_MSD_id_list = []\n",
    "recording_mbid_list = []\n",
    "for i in range(len(cleaned_file_paths)):\n",
    "    curr_path = file_paths[i]\n",
    "    curr_MSD_id = curr_path.split('/')[-2]\n",
    "    cleaned_MSD_id_list.append(curr_MSD_id)\n",
    "for i in range(len(matched_file_paths)):\n",
    "    curr_path = file_paths[i]\n",
    "    curr_MSD_id = curr_path.split('/')[-2]\n",
    "    uncleaned_MSD_id_list.append(curr_MSD_id)\n",
    "    recording_mbid_list.append(curr_path.split('/')[-1].split('.')[0])\n",
    "unique_uncleaned_MSD_id_list = list(set(uncleaned_MSD_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "507c6b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = []\n",
    "tuple_list = []\n",
    "DATA_LENGTH = 20000\n",
    "NUM_FILE = 100\n",
    "CLEANED = False\n",
    "\n",
    "idx = 0\n",
    "while len(tuple_list) < NUM_FILE:\n",
    "    MSD_ids = cleaned_MSD_id_list if CLEANED else unique_uncleaned_MSD_id_list\n",
    "    curr_path = cleaned_file_paths[idx] if CLEANED else matched_file_paths[idx]\n",
    "    idx += 1\n",
    "    curr_MSD_id = curr_path.split('/')[-2]\n",
    "    curr_amazon_id = mumu_multi_df.loc[mumu_multi_df['MSD_track_id'] == curr_MSD_id]\n",
    "    \n",
    "    if len(curr_amazon_id) == 0:\n",
    "        curr_amazon_id = mumu_single_df.loc[mumu_single_df['MSD_track_id'] == curr_MSD_id]\n",
    "        if len(curr_amazon_id) == 0:\n",
    "            continue\n",
    "            \n",
    "    npz = np.load(curr_path)\n",
    "    df= pd.DataFrame.from_dict({item: npz[item] for item in npz.files}, orient='index').T\n",
    "    data_nparr = df[['pianoroll_0_csc_data', 'pianoroll_1_csc_data', 'pianoroll_2_csc_data', 'pianoroll_3_csc_data', 'pianoroll_4_csc_data']].fillna(0).to_numpy()\n",
    "    if data_nparr.shape[0] > DATA_LENGTH:\n",
    "        data_nparr = data_nparr[:DATA_LENGTH + 1]\n",
    "    elif data_nparr.shape[0] < DATA_LENGTH:\n",
    "        np.pad(data_nparr, (0, DATA_LENGTH - data_nparr.shape[0]), 'constant', constant_values=(0, 0))\n",
    "\n",
    "    curr_review = mumu_amazon_df.loc[mumu_amazon_df['amazon_id'] == curr_amazon_id['amazon_id'].values[0]]['reviewText']\n",
    "    curr_tuple = [data_nparr.tolist(), curr_review.values[0]]\n",
    "    tuple_list.append(curr_tuple)\n",
    "    label_list.append(curr_review.values[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c65d06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_tuple_list = []\n",
    "for tuples in tuple_list:\n",
    "    neg_label = tuples[1]\n",
    "    while neg_label == tuples[1]:\n",
    "        neg_label = random.choice(label_list)\n",
    "    neg_tuple = [tuples[0], neg_label]\n",
    "    neg_tuple_list.append(neg_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b3dffa65",
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TUPLE_PATH = \"pos_tuples_mini.csv\"\n",
    "NEG_TUPLE_PATH = \"neg_tuples_mini.csv\"\n",
    "fields = ['data', 'label'] \n",
    "with open(POS_TUPLE_PATH, 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(fields)\n",
    "    write.writerows(tuple_list)\n",
    "with open(NEG_TUPLE_PATH, 'w') as f:\n",
    "    write = csv.writer(f)\n",
    "    write.writerow(fields)\n",
    "    write.writerows(neg_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "edc77525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(neg_tuple_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0572ab5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mintime: 1824\n",
    "#maxtime: 166926\n",
    "#avgtime of first 100: 31551.36\n",
    "\n",
    "#number of cleaned pianoroll tracks: 21425\n",
    "#cleaned tracks matched to unique labels: 2504 / 1916 / 1701 / 1816\n",
    "#all matching labels of cleaned tracks: 39776 / 40172\n",
    "\n",
    "#number of uncleaned pianoroll recordings: 115160\n",
    "#unique uncleaned tracks matched to unique labels: 3559 / 3328\n",
    "#all matching labels of unique uncleaned tracks: 76861\n",
    "#all uncleaned recordings matched to repetative lablels: 11697\n",
    "\n",
    "#size of entire mumudataset: 956292\n",
    "# There may be multiple reviews to the same MSD track!!!\n",
    "\n",
    "#count pianoroll matched to amazon review\n",
    "count = 0\n",
    "count_review = 0\n",
    "for idd in unique_uncleaned_MSD_id_list:\n",
    "    curr_amazon_id = mumu_single_df.loc[mumu_single_df['MSD_track_id'] == idd]\n",
    "    if len(curr_amazon_id) == 0:\n",
    "        curr_amazon_id = mumu_multi_df.loc[mumu_multi_df['MSD_track_id'] == idd]\n",
    "        if len(curr_amazon_id) == 0:\n",
    "            continue\n",
    "    curr_review = mumu_amazon_df.loc[mumu_amazon_df['amazon_id'] == curr_amazon_id['amazon_id'].values[0]]['reviewText']\n",
    "    count += 1\n",
    "    count_review += len(curr_review.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1b14ae25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3328 76861\n"
     ]
    }
   ],
   "source": [
    "print(count, count_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58eae6d7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
